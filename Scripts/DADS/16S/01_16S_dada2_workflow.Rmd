---
title: "16S DADA2 Workflow"
output: html_document
date: "2024-06-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/SOD_DADS_microbiome/Data/16S")

library(phyloseq); packageVersion("phyloseq")
library(ggplot2); packageVersion("ggplot2")
library(dada2); packageVersion("dada2")
library(dada2); packageVersion("Biostrings")
library(ShortRead); packageVersion("ShortRead")
```

### Workflow is similar to what is described in the 16S tutorial in DADA2 documentation
Remove Ns from any reads before beginning DADA2 workflow
```{r remove Ns}
path <- "reads"
list.files(path)

fnFs <- sort(list.files(path, pattern="_R1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2.fastq.gz", full.names = TRUE))

#Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- gsub("_R1.fastq.gz", "", basename(fnFs))

#Set up directory structure of output files
fnFs.prefilt <- file.path(path, "prefiltered", basename(fnFs))
fnRs.prefilt <- file.path(path, "prefiltered", basename(fnRs))

out <- filterAndTrim(fnFs, fnFs.prefilt, fnRs, fnRs.prefilt, maxN=0, compress=TRUE, multithread=TRUE)
```

### Get stats on primer counts before running Cutadapt 
```{r get primer counts}
FWD <- "GTGYCAGCMGCCGCGGTAA"  
REV <- "GGACTACNVGGGTWTCTAAT" 

allOrients <- function(primer) {
    # Create all orientations of the input sequence
    require(Biostrings)
    dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
    orients <- c(Forward = dna, Complement = Biostrings::complement(dna), Reverse = Biostrings::reverse(dna),
        RevComp = Biostrings::reverseComplement(dna))
    return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
FWD.orients

primerHits <- function(primer, fn) {
    # Counts number of reads in which the primer is found
    nh16S <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
    return(sum(nh16S > 0))
}

rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.prefilt[[1]]), FWD.ReverseReads = sapply(FWD.orients,
    primerHits, fn = fnRs.prefilt[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits,
    fn = fnFs.prefilt[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.prefilt[[1]]))
```

### Run Cutadapt to remove any residual primers (there shouldn't be many because Earth Microbiome protocol was followed)
```{r run cutadapt}
cutadapt <- "/usr/bin/cutadapt"
system2(cutadapt, args = "--version") # Run shell commands from R

path.cut <- file.path(path, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs.cut <- file.path(path.cut, basename(fnFs))
fnRs.cut <- file.path(path.cut, basename(fnRs))

FWD.RC <- dada2:::rc(FWD)
REV.RC <- dada2:::rc(REV)
# Trim FWD and the reverse-complement of REV off of R1 (forward reads)
R1.flags <- paste("-g", FWD, "-a", REV.RC) 
# Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
R2.flags <- paste("-G", REV, "-A", FWD.RC) 
# Run Cutadapt
for(i in seq_along(fnFs)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
                             "-o", fnFs.cut[i], "-p", fnRs.cut[i], 
                             "--minimum-length", 50,
                             fnFs.prefilt[i], fnRs.prefilt[i]))}
```

### Get stats on primer counts after running cutadapt 
```{r get post-trim primer counts}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), FWD.ReverseReads = sapply(FWD.orients,
    primerHits, fn = fnRs.cut[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits,
    fn = fnFs.cut[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))
```

### Now we will inspect read quality profiles
``` {r plot qualityp rofiles}
# Forward and reverse fastq filenames have the format:
cutFs <- sort(list.files(path.cut, pattern = "_R1.fastq.gz", full.names = TRUE))
cutRs <- sort(list.files(path.cut, pattern = "_R2.fastq.gz", full.names = TRUE))

sample.names <- gsub("_R1.fastq.gz", "", basename(cutFs))

plotQualityProfile(cutFs[1:5])
plotQualityProfile(cutRs[1:5])
```

### Run core filterAndTrim command from DADA2 to remove any poor quality reads
```{r filter and trim reads}
filtFs <- file.path(path.cut, "filtered", basename(cutFs))
filtRs <- file.path(path.cut, "filtered", basename(cutRs))

out <- filterAndTrim(cutFs, filtFs, cutRs, filtRs, maxN = 0, maxEE = c(2,2), truncQ = 2,
    minLen = 0, maxLen = Inf, rm.phix = TRUE, compress = TRUE, multithread = TRUE) 
head(out)

out
```

### Now we will learn error rates and do the key sample inference step
``` {r learn error rates}
set.seed(1)
names(filtFs) <- sample.names
names(filtRs) <- sample.names

errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)

plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)

dadaFs <- dada(filtFs, err = errF, multithread = TRUE)
dadaRs <- dada(filtRs, err = errR, multithread = TRUE)
```

### We will merge paired reads
``` {r merged paired}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs,  minOverlap = 12, maxMismatch = 2, verbose=TRUE)
```

### We will then construct a sequence table
``` {r construct sequence table}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

### Finally, we will remove chimeras
``` {r remove chimeras}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
table(nchar(getSequences(seqtab.nochim)))


write.table(seqtab.nochim, file="dada2_outputs/16S_seqtab_nochim.out",sep="\t",quote=F)
```

### At the end, we will track reads through the full DADA2 pipeline
``` {r plotqualityprofiles}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN),
    rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace
# sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track)<-gsub("_R1.fastq.gz", "", rownames(track))
head(track)

write.table(track, file="dada2_outputs/16S_trackreads.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy
``` {r assignTaxonomy without tryRC}
set.seed(1)
sixteensdb.ref <- "metadata_dbs/silva_nr99_v138.1_wSpecies_train_set.fa"  # CHANGE ME to location on your machine
taxa <- assignTaxonomy(seqtab.nochim, sixteensdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = FALSE)

taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL

write.table(taxa, file="dada2_outputs/16S_taxa.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy but with tryRC option
``` {r assignTaxonomy with tryRC}
set.seed(1)
sixteensdb.ref <- "metadata_dbs/silva_nr99_v138.1_wSpecies_train_set.fa"  # CHANGE ME to location on your machine
taxa <- assignTaxonomy(seqtab.nochim, sixteensdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = TRUE)

taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL

write.table(taxa, file="dada2_outputs/16S_taxa_RC.out",sep="\t",quote=F)
```

### Let's try again with separate species specific db
``` {r assignTaxonomy with separate species db}
set.seed(1)
sixteensdb_nospecies.ref <- "metadata_dbs/silva_nr99_v138.1_train_set.fa"  # CHANGE ME to location on your machine
species.ref <- "metadata_dbs/silva_species_assignment_v138.1.fa"
taxa2 <- assignTaxonomy(seqtab.nochim, sixteensdb_nospecies.ref, multithread = TRUE, minBoot = 0, verbose=TRUE, tryRC = FALSE)
taxa2 <- addSpecies(taxa2, species.ref)

taxa.print2 <- taxa  # Removing sequence rownames for display only
rownames(taxa.print2) <- NULL

write.table(taxa2, file="dada2_outputs/16S_taxa_species_separate.out",sep="\t",quote=F)
```

### Let's try again with separate species specific db and tryRC=TRUE
``` {r assignTaxonomy with separate species db and tryRC is TRUE}
set.seed(1)
sixteensdb_nospecies.ref <- "metadata_dbs/silva_nr99_v138.1_train_set.fa"  # CHANGE ME to location on your machine
species.ref <- "metadata_dbs/silva_species_assignment_v138.1.fa"
taxa2 <- assignTaxonomy(seqtab.nochim, sixteensdb_nospecies.ref, multithread = TRUE, minBoot = 0, verbose=TRUE, tryRC = TRUE)
taxa2 <- addSpecies(taxa2, species.ref)

taxa.print2 <- taxa  # Removing sequence rownames for display only
rownames(taxa.print2) <- NULL

write.table(taxa2, file="dada2_outputs/16S_taxa_species_separate_rctrue.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy but with minBoot set to 60
``` {r assignTaxonomy with minBoot at 60 and separate species db}
set.seed(1)
sixteensdb_nospecies.ref <- "metadata_dbs/silva_nr99_v138.1_train_set.fa"  # CHANGE ME to location on your machine
species.ref <- "metadata_dbs/silva_species_assignment_v138.1.fa"
taxa2 <- assignTaxonomy(seqtab.nochim, sixteensdb_nospecies.ref, multithread = TRUE, minBoot = 60, verbose=TRUE, tryRC = FALSE)
taxa2 <- addSpecies(taxa2, species.ref)

taxa.print2 <- taxa  # Removing sequence rownames for display only
rownames(taxa.print2) <- NULL

write.table(taxa2, file="dada2_outputs/16S_taxa_species_separate_minboot60.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy but with minBoot set to 60 and try RC
``` {r assignTaxonomy with minBoot at 60}
set.seed(1)
sixteensdb_nospecies.ref <- "metadata_dbs/silva_nr99_v138.1_train_set.fa"  # CHANGE ME to location on your machine
species.ref <- "metadata_dbs/silva_species_assignment_v138.1.fa"
taxa2 <- assignTaxonomy(seqtab.nochim, sixteensdb_nospecies.ref, multithread = TRUE, minBoot = 60, verbose=TRUE, tryRC = TRUE)
taxa2 <- addSpecies(taxa2, species.ref)

taxa.print2 <- taxa  # Removing sequence rownames for display only
rownames(taxa.print2) <- NULL

write.table(taxa2, file="dada2_outputs/16S_taxa_species_separate_minboot60_RC.out",sep="\t",quote=F)
```

```{r}
sessioninfo::session_info()
```