---
title: "01_dada2_workflow_its"
output: html_document
date: "2024-06-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/DADS/Data/ITS/")

library(phyloseq); packageVersion("phyloseq")
library(ggplot2); packageVersion("ggplot2")
library(dada2); packageVersion("dada2")
library(dada2); packageVersion("Biostrings")
library(ShortRead); packageVersion("ShortRead")
```

### Workflow is similar to what is described in the ITS tutorial in DADA2 documentation

### Remove Ns from any reads before beginning DADA2 workflow
```{r remove Ns}
path <- "reads"
list.files(path)

fnFs <- sort(list.files(path, pattern="_L001_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_L001_R2_001.fastq.gz", full.names = TRUE))

#Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- gsub("_L001_R1_001.fastq.gz", "", basename(fnFs))

#Set up directory structure of output files
fnFs.prefilt <- file.path(path, "prefiltered", basename(fnFs))
fnRs.prefilt <- file.path(path, "prefiltered", basename(fnRs))

out <- filterAndTrim(fnFs, fnFs.prefilt, fnRs, fnRs.prefilt, maxN=0, compress=TRUE, multithread=TRUE)
```

### Get stats on primer counts before running Cutadapt 
```{r get primer counts}
FWD <- "GTGARTCATCGAATCTTTG"  
REV <- "TCCTSCGCTTATTGATATGC"

allOrients <- function(primer) {
    # Create all orientations of the input sequence
    require(Biostrings)
    dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
    orients <- c(Forward = dna, Complement = Biostrings::complement(dna), Reverse = Biostrings::reverse(dna),
        RevComp = Biostrings::reverseComplement(dna))
    return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
FWD.orients

primerHits <- function(primer, fn) {
    # Counts number of reads in which the primer is found
    nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
    return(sum(nhits > 0))
}

rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.prefilt[[1]]), FWD.ReverseReads = sapply(FWD.orients,
    primerHits, fn = fnRs.prefilt[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits,
    fn = fnFs.prefilt[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.prefilt[[1]]))
```

### Run Cutadapt to remove primers
```{r run cutadapt}
cutadapt <- "/usr/bin/cutadapt"
system2(cutadapt, args = "--version") # Run shell commands from R

path.cut <- file.path(path, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs.cut <- file.path(path.cut, basename(fnFs))
fnRs.cut <- file.path(path.cut, basename(fnRs))

FWD.RC <- dada2:::rc(FWD)
REV.RC <- dada2:::rc(REV)
# Trim FWD and the reverse-complement of REV off of R1 (forward reads)
R1.flags <- paste("-g", FWD, "-a", REV.RC) 
# Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
R2.flags <- paste("-G", REV, "-A", FWD.RC) 
# Run Cutadapt
for(i in seq_along(fnFs)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
                             "-o", fnFs.cut[i], "-p", fnRs.cut[i], 
                             "--minimum-length", 50,
                             # output files
                             fnFs.prefilt[i], fnRs.prefilt[i]))}
```

### Get stats on primer counts after running cutadapt 
```{r get post-trim primer counts}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), FWD.ReverseReads = sapply(FWD.orients,
    primerHits, fn = fnRs.cut[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits,
    fn = fnFs.cut[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))
```

### Now we will inspect read quality profiles
``` {r plot qualityp rofiles}
# Forward and reverse fastq filenames have the format:
cutFs <- sort(list.files(path.cut, pattern = "_L001_R1_001.fastq.gz", full.names = TRUE))
cutRs <- sort(list.files(path.cut, pattern = "_L001_R2_001.fastq.gz", full.names = TRUE))

plotQualityProfile(cutFs[1:5])
plotQualityProfile(cutRs[1:5])
```

### Run core filterAndTrim command from DADA2 to remove any poor quality reads
```{r filter and trim reads}
filtFs <- file.path(path.cut, "filtered", basename(cutFs))
filtRs <- file.path(path.cut, "filtered", basename(cutRs))

out <- filterAndTrim(cutFs, filtFs, cutRs, filtRs, maxN = 0, maxEE = c(2,2), truncQ = 2,
    minLen = 50, maxLen = Inf, rm.phix = TRUE, compress = TRUE, multithread = TRUE) 
head(out)
```

### Now we will learn error rates and do the key sample inference step
``` {r learn error rates}
set.seed(1)
names(filtFs) <- sample.names
names(filtRs) <- sample.names

errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)

plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)

dadaFs <- dada(filtFs, err = errF, multithread = TRUE)
dadaRs <- dada(filtRs, err = errR, multithread = TRUE)
```

### We will merge paired reads
``` {r merged paired}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs,  minOverlap = 12, maxMismatch = 2, verbose=TRUE)
```

### We will then construct a sequence table
``` {r construct sequence table}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

### Finally, we will remove chimeras
``` {r remove chimeras}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
table(nchar(getSequences(seqtab.nochim)))


write.table(seqtab.nochim, file="dada2_outputs/its_seqtab_nochim.out",sep="\t",quote=F)
```

### At the end, we will track reads through the full DADA2 pipeline
``` {r plotqualityprofiles}
getN <- function(x)sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN),
    rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace
# sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")

rownames(track)<-gsub("_L001_R1_001.fastq.gz", "", rownames(track))
head(track)

write.table(track, file="dada2_outputs/its_trackreads.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy
``` {r assignTaxonomy}
# set.seed(1)
# itsdb.ref <- "metadata_dbs/sh_general_release_dynamic_all_04.04.2024.fasta"  # CHANGE ME to location on your machine
# taxa <- assignTaxonomy(seqtab.nochim, itsdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = FALSE)
# 
# taxa.print <- taxa  # Removing sequence rownames for display only
# rownames(taxa.print) <- NULL
# 
# write.table(taxa, file="dada2_outputs/its_taxa_04_2024.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy but with tryRC option
``` {r assignTaxonomy with tryRC}
# set.seed(1)
# itsdb.ref <- "metadata_dbs/sh_general_release_dynamic_all_04.04.2024.fasta"  # CHANGE ME to location on your machine
# taxa <- assignTaxonomy(seqtab.nochim, itsdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = TRUE)
# 
# taxa.print <- taxa  # Removing sequence rownames for display only
# rownames(taxa.print) <- NULL
# 
# write.table(taxa, file="dada2_outputs/its_taxa_04_2024_tryRC.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy but only fungidb
``` {r assignTaxonomy only fungi db}
# set.seed(1)
# itsdb_fung.ref <- "metadata_dbs/sh_general_release_dynamic_04.04.2024.fasta"  
# taxa <- assignTaxonomy(seqtab.nochim, itsdb_fung.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = FALSE)
# 
# taxa.print <- taxa  # Removing sequence rownames for display only
# rownames(taxa.print) <- NULL
# 
# write.table(taxa, file="dada2_outputs/its_taxa_unitefungi_04_2024.out",sep="\t",quote=F)
```

### If everything look good, let's assign taxonomy but only fungi db
``` {r assignTaxonomy fungi db try rc}
# set.seed(1)
# itsdb_fung.ref <- "metadata_dbs/sh_general_release_dynamic_04.04.2024.fasta"  # CHANGE ME to location on your machine
# taxa <- assignTaxonomy(seqtab.nochim, itsdb_fung.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = TRUE)
# 
# taxa.print <- taxa  # Removing sequence rownames for display only
# rownames(taxa.print) <- NULL
# 
# write.table(taxa, file="dada2_outputs/its_taxa_unitefungi_04_2024_RC.out",sep="\t",quote=F)
```

### Let's try db released in 2023 (larger)
``` {r assignTaxonomy unite all 2023}
set.seed(1)
itsdb.ref <- "metadata_dbs/sh_general_release_dynamic_all_25.07.2023.fasta"  # CHANGE ME to location on your machine
taxa <- assignTaxonomy(seqtab.nochim, itsdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = FALSE)

taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL

write.table(taxa, file="dada2_outputs/its_taxa_07_2023.out",sep="\t",quote=F)
```

### Let's try db released in 2023 but with tryRC option
``` {r assignTaxonomy unite 2023 with tryRC}
set.seed(1)
itsdb.ref <- "metadata_dbs/sh_general_release_dynamic_all_25.07.2023.fasta"  # CHANGE ME to location on your machine
taxa <- assignTaxonomy(seqtab.nochim, itsdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = TRUE)

taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL

write.table(taxa, file="dada2_outputs/its_taxa_07_2023_tryRC.out",sep="\t",quote=F)
```

### Finally, let's try latest db (04-2024) release, but larger db with global and 3% distance singletons
``` {r assignTaxonomy unite with singletons latest}
set.seed(1)
itsdb.ref <- "metadata_dbs/sh_general_release_dynamic_s_all_25.07.2023.fasta"  # CHANGE ME to location on your machine
taxa <- assignTaxonomy(seqtab.nochim, itsdb.ref, multithread = TRUE, minBoot = 0, outputBootstraps = TRUE, verbose=TRUE, tryRC = FALSE)

taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL

write.table(taxa, file="dada2_outputs/its_taxa_07_2023_3distsingletons.out",sep="\t",quote=F)
```

```{r}
sessioninfo::session_info()
```